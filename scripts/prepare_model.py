import os
import subprocess
import sys
import importlib

def install_and_import(package):
    """CÃ i Ä‘áº·t vÃ  nháº­p thÆ° viá»‡n."""
    try:
        importlib.import_module(package)
    except ImportError:
        print(f"Äang cÃ i Ä‘áº·t {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package, "--quiet"])
    finally:
        globals()[package] = importlib.import_module(package)

# --- HÃ m Ä‘á»ƒ cháº¡y lá»‡nh vÃ  kiá»ƒm tra lá»—i ---
def run_command(command):
    """Cháº¡y má»™t lá»‡nh trong shell vÃ  in ra output."""
    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
    stdout, stderr = process.communicate()
    if process.returncode != 0:
        print(f"Lá»—i khi cháº¡y lá»‡nh: {command}")
        print(stderr.decode('utf-8'))
    else:
        print(stdout.decode('utf-8'))

# --- Báº¯t Ä‘áº§u quy trÃ¬nh ---
print("--- Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh chuáº©n bá»‹ model ---")
print("Vui lÃ²ng chá», quÃ¡ trÃ¬nh nÃ y sáº½ máº¥t khoáº£ng 5-10 phÃºt tÃ¹y thuá»™c vÃ o tá»‘c Ä‘á»™ cá»§a Colab.")

# --- BÆ°á»›c 1: CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t ---
# Äáº£m báº£o cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t
print("\n[BÆ°á»›c 1/4] Äang cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t...")
try:
    install_and_import("transformers")
    install_and_import("torch")
    install_and_import("huggingface_hub")
    print("CÃ i Ä‘áº·t hoÃ n táº¥t!")
except Exception as e:
    print(f"Lá»—i khi cÃ i Ä‘áº·t thÆ° viá»‡n: {e}")
    sys.exit()

# Táº£i cÃ¡c module sau khi Ä‘Ã£ cÃ i Ä‘áº·t
from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq

# --- BÆ°á»›c 2: Táº£i Model vÃ  Processor tá»« Hugging Face ---
# ÄÃ¢y lÃ  model AI nháº­n diá»‡n giá»ng nÃ³i tá»‘t nháº¥t vÃ  má»›i nháº¥t
MODEL_NAME = "openai/whisper-large-v3"
print(f"\n[BÆ°á»›c 2/4] Äang táº£i processor vÃ  model 'xá»‹n' nháº¥t tá»«: {MODEL_NAME}")
try:
    processor = AutoProcessor.from_pretrained(MODEL_NAME)
    model = AutoModelForSpeechSeq2Seq.from_pretrained(MODEL_NAME)
    print("Táº£i model thÃ nh cÃ´ng!")
except Exception as e:
    print(f"ÄÃ£ xáº£y ra lá»—i khi táº£i model: {e}")
    sys.exit()

# --- BÆ°á»›c 3: LÆ°u Model vÃ  Processor vÃ o thÆ° má»¥c local ---
SAVE_DIRECTORY = "./whisper-large-v3-local"
print(f"\n[BÆ°á»›c 3/4] Äang lÆ°u model vÃ o thÆ° má»¥c: {SAVE_DIRECTORY}")
try:
    if not os.path.exists(SAVE_DIRECTORY):
        os.makedirs(SAVE_DIRECTORY)
        
    model.save_pretrained(SAVE_DIRECTORY)
    processor.save_pretrained(SAVE_DIRECTORY)
    print("LÆ°u model thÃ nh cÃ´ng!")
except Exception as e:
    print(f"ÄÃ£ xáº£y ra lá»—i khi lÆ°u model: {e}")
    sys.exit()

# --- BÆ°á»›c 4: NÃ©n thÆ° má»¥c Ä‘á»ƒ táº£i vá» ---
ZIP_FILE_NAME = "whisper_model.zip"
print(f"\n[BÆ°á»›c 4/4] Äang nÃ©n thÆ° má»¥c '{SAVE_DIRECTORY}' thÃ nh file '{ZIP_FILE_NAME}'...")
run_command(f"zip -r -q {ZIP_FILE_NAME} {SAVE_DIRECTORY}")

print("\n--- ğŸ‰ HOÃ€N Táº¤T! ---")
print(f"Má»™t file tÃªn lÃ  '{ZIP_FILE_NAME}' Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng.")
print("-> HÃ£y tÃ¬m nÃ³ á»Ÿ thanh file bÃªn trÃ¡i cá»§a Colab, nháº¥n chuá»™t pháº£i vÃ  chá»n 'Download' Ä‘á»ƒ táº£i vá» mÃ¡y.")

